"""
FastAPI ë°±ì—”ë“œ ì„œë²„
- íƒˆ ì¶”ì²œ API ì œê³µ
"""
import os
from pathlib import Path
from typing import List
from contextlib import asynccontextmanager

import torch
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from PIL import Image
import io

from model import load_model, extract_embedding, EXPRESSION_CLASSES
from mask_index import build_mask_index, compute_recommendations, MaskInfo


# ============== ì„¤ì • ==============
MODEL_PATH = os.environ.get("MODEL_PATH", "expression_resnet18_best.pth")
MASKS_DIR = os.environ.get("MASKS_DIR", "masks")
TOP_K = int(os.environ.get("TOP_K", "3"))
COSINE_WEIGHT = float(os.environ.get("COSINE_WEIGHT", "0.7"))
EXPRESSION_WEIGHT = float(os.environ.get("EXPRESSION_WEIGHT", "0.3"))

# ============== ì „ì—­ ë³€ìˆ˜ ==============
device: torch.device = None
model = None
mask_index: List[MaskInfo] = []


# ============== Pydantic ëª¨ë¸ ==============
class MaskRecommendation(BaseModel):
    mask_path: str
    mask_name: str
    cosine_similarity: float
    expression_match: bool
    mask_expression: str
    combined_score: float


class RecommendationResponse(BaseModel):
    face_expression: str
    recommendations: List[MaskRecommendation]


# ============== Lifespan (ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰) ==============
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ê³¼ íƒˆ ì¸ë±ìŠ¤ ë¡œë“œ"""
    global device, model, mask_index
    
    print("=" * 50)
    print("ğŸ­ íƒˆ ì¶”ì²œ ì„œë²„ ì´ˆê¸°í™” ì¤‘...")
    print("=" * 50)
    
    # Device ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Device: {device}")
    
    # ëª¨ë¸ ë¡œë“œ
    if not os.path.exists(MODEL_PATH):
        print(f"âš  ê²½ê³ : ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        print("  â†’ ëª¨ë¸ íŒŒì¼ì„ backend/ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    else:
        model = load_model(MODEL_PATH, device)
        
        # íƒˆ ì¸ë±ìŠ¤ ë¹Œë“œ
        mask_index = build_mask_index(MASKS_DIR, model, device)
    
    print("=" * 50)
    print("âœ“ ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
    print(f"  - ë¡œë“œëœ íƒˆ ì´ë¯¸ì§€: {len(mask_index)}ê°œ")
    print("=" * 50)
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    print("ì„œë²„ ì¢…ë£Œ ì¤‘...")


# ============== FastAPI ì•± ==============
app = FastAPI(
    title="íƒˆ ì¶”ì²œ API",
    description="ì–¼êµ´ ì‚¬ì§„ ê¸°ë°˜ í•œêµ­ ì „í†µ íƒˆ ì¶”ì²œ ì„œë¹„ìŠ¤",
    version="1.0.0",
    lifespan=lifespan
)

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œì™€ í†µì‹  í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ì „ì²´ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ============== ì—”ë“œí¬ì¸íŠ¸ ==============
@app.get("/")
async def root():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "ok",
        "model_loaded": model is not None,
        "mask_count": len(mask_index)
    }


@app.post("/recommend", response_model=RecommendationResponse)
async def recommend(file: UploadFile = File(...)):
    """
    ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ì–´ìš¸ë¦¬ëŠ” íƒˆì„ ì¶”ì²œ
    
    Args:
        file: ì—…ë¡œë“œëœ ì–¼êµ´ ì´ë¯¸ì§€ íŒŒì¼
    
    Returns:
        face_expression: ê°ì§€ëœ ì–¼êµ´ í‘œì •
        recommendations: ì¶”ì²œëœ íƒˆ ëª©ë¡ (TOP_Kê°œ)
    """
    if model is None:
        raise HTTPException(
            status_code=503,
            detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
    
    if not mask_index:
        raise HTTPException(
            status_code=503,
            detail="íƒˆ ì´ë¯¸ì§€ê°€ ì¸ë±ì‹±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. masks/ í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
    
    # íŒŒì¼ íƒ€ì… ê²€ì¦
    if not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=400,
            detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))
        
        # ì„ë² ë”© ë° í‘œì • ì¶”ì¶œ
        face_embedding, face_expr_idx, face_expr_label = extract_embedding(
            model, image, device
        )
        
        # ì¶”ì²œ ê³„ì‚°
        recommendations = compute_recommendations(
            face_embedding=face_embedding,
            face_expression_idx=face_expr_idx,
            mask_index=mask_index,
            top_k=TOP_K,
            cosine_weight=COSINE_WEIGHT,
            expression_weight=EXPRESSION_WEIGHT
        )
        
        return RecommendationResponse(
            face_expression=face_expr_label,
            recommendations=[MaskRecommendation(**rec) for rec in recommendations]
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@app.get("/masks/{mask_path:path}")
async def get_mask_image(mask_path: str):
    """íƒˆ ì´ë¯¸ì§€ íŒŒì¼ ì œê³µ"""
    full_path = Path(MASKS_DIR) / mask_path
    
    if not full_path.exists():
        raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    return FileResponse(full_path)


@app.get("/expressions")
async def get_expressions():
    """ì‚¬ìš© ê°€ëŠ¥í•œ í‘œì • í´ë˜ìŠ¤ ëª©ë¡"""
    return {"expressions": EXPRESSION_CLASSES}


# ============== ì‹¤í–‰ ==============
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )
